I devised a model that is less sensitive or even insensitive to
non monotonic distributions of the presentation score, by turning the
presentation score into a secondary rather than primary explanatory
covariate.

We want to model the general rate at which mutations yield neo-antigens
($n$) for a particular tumor type $y$ and how that rate is modulated
by the presentation score ($p$) for the focus allele of the analysis.
We thus arrive at:

$$
n_i = m_i y_i \\
y_i = \beta_y + \beta_p p_i
$$

where $n_i$, $m_i$ are the neo-antigen and mutational load,
respectively, for patient $i$ and
$y_i$ is the patient specific yield rate, consisting of
a global neo-antigen yield rate $\beta_y$ and a term that describes the degree to
which the HLA presentation capability (modeled by the presentation
score) shifts this global yield-rate in a patient-specific manner. This second second term consists of
the patient-specific presentation score $p_i$ and $\beta_p$, the
fractional degree to which $y$ is modulated by a unit incease in
$p_i$. Combined, this gives $n_i = m_i (\beta_y + \beta_p p_i)$, removing coefficients ($\beta_y$ and $\beta_p$), we get the following R model formula to be used in a glm:

$$
n_i \sim 0 + m_i + m_i:p_i
$$

where the 0 forces no intercept term to be fitted, the first
coefficient represents $\beta_y$ and the second $\beta_p$.

We're ultimately interested in the mean fractional difference $\delta$
in neo-antigen yield rate between patients with
$p = 1$ and $p = 0$, which is

$$
\delta = \frac{(\beta_y + \beta_p) - (\beta_y - 0 \beta_p)}{\beta_y - 0 \beta_p} = \frac{\beta_p}{\beta_y}
$$

```{r, init, include=F, warning=FALSE}
source('~/antigenic_space/bin/init.R')

source(file.path(IE_root, 'continuous_IE_detection_init.R'))

reg_method = 'rlm_high_TMB_patients'
reg_method = 'rlm'
reg_method = 'glm'
ncores = 36
ncores = 1
ncores = 20

filtering <- function(dtf) {
  filter_coef_overview(
    dtf = dtf,
    min_patients = 20,
    min_project_size = 250,
    intercept_filter_p_val = .05,
    intercept_filter_magnitude = 1e-2,
    force_positive_intercept = F
    # delta_SE_filter = .2
  )
}

f_setting_dtf <-
  compile_all_coef_overview(
    redo = F,
    redo_subanalyses = F,
    check_data_availability = F,
    skip_missing = F,
    # N_downsample_settings = 50,
    ncores = ncores,
    reg_method = reg_method,
    include_non_ds_tallies = T,
    z_normalize = F
  ) %>%
  annotate_pipeline_settings() %>%
  filtering

```

Averaging over all settings, we now get a very subtle shift towards IE (negative $\delta$):

```{r, warning=FALSE, results='asis', width='50%'}
#' show all and summary
saas <- function(dtf) {
  # dtf <- dtf[unlist(message) == 'OK']
  dtf <- dtf[order(V1)]
  print(knitr::kable(head(dtf, n = 30L)))
  print(knitr::kable(dtf[, enframe(summary(V1))]))
}

f_setting_dtf[, median(delta), by = project_extended] %>%
  saas()

## Low deviation from zero in permutations :)
f_setting_dtf[, median(perm_delta_median), by = project_extended] %>%
  saas()

## Observed stats only lightly deviate from permutated distributions
f_setting_dtf[, median(perm_delta_pq), by = project_extended] %>%
  saas()
```

Define a normalized $\delta$, $\delta_n$, as $\delta - \delta_r$, where
$\delta_r$ is the median of random permutation $\delta$'s.

```{r, warning=FALSE}
f_setting_dtf[, 'delta_n' := delta - perm_delta_median]

## Fraction of analyses with truly aberrant results
print(mean(abs(f_setting_dtf$delta_n) > 1))

f_setting_dtf <- f_setting_dtf[abs(delta_n) <= 1]
```

```{r, results='asis'}
f_setting_dtf[, median(delta_n),
  by = 'project_extended'][order(V1)] %>%
  saas()

id_vars <- c('project_extended', 'focus_allele', 'analysis_idx',
  'overlap_var', 'patient_inclusion_crit', 'LOH_HLA', 'analysis_name')

# f_setting_dtf[, median(delta_n),
#   by = id_vars][order(V1)] %>%
#   saas()

# f_setting_dtf[, median(delta_n),
#   by = c('project_extended', 'analysis_idx')][,
#   median(V1), by = analysis_idx][order(V1)] %>%
#   saas()
```

Perhaps the subtle shift would get more substantial if we isolate the more
sensitive settings (RISK OF OVERFITTING!)?
Find which combination of settings are most likely to indicate editing across
tumor types.

```{r, include=F, eval=F}
# max_N <- 100L
# max_N <- nrow(analysis_idx_o)
# vn <- 'focus_allele'
# lev <- 'A1101'
calcGseaStat(
  stats = 1:10,
  selectedStats = 1,
  # scoreType = 'pos'
  scoreType = 'std'
)
```

```{r, warning=FALSE, results='asis'}
id_vars <- c('project_extended', 'focus_allele', 'analysis_idx',
  'overlap_var', 'patient_inclusion_crit', 'LOH_HLA', 'analysis_name')
analysis_idx_o <-
  f_setting_dtf[, median(delta_n),
  by = setdiff(id_vars, 'project_extended')]

analysis_idx_o <-
  analysis_idx_o %>%
  dplyr::filter(abs(V1) <= 1) %>%
  .[, median(V1), by = setdiff(colnames(analysis_idx_o), 'V1')] %>%
  .[order(V1)] %>%
  { cbind(., ds_param_grid[.[, analysis_idx], ]) } %>%
  { . }

for (vn in c(setdiff(id_vars, 'analysis_idx'), 
    colnames(ds_param_grid))) {
  output <- tryCatch(test_fe(vn), error = function(e) { NULL })
  if (!maartenutils::null_dat(output)) {
    print(knitr::kable(output))
  }
}
```

```{r, include=F, eval=F}
## Results don't make sense
factor_to_pw <- function(fac) {
  purrr::map(maartenutils::auto_name(levels(fac)), ~.x)
}
fgseaMultilevel(
  pathways = factor_to_pw(analysis_idx_o$focus_allele),
  stats = setNames(
    1:nrow(analysis_idx_o)-.5 * nrow(analysis_idx_o), 
    analysis_idx_o$focus_allele
  )
  # scoreType = 'pos'
)
```

```{r, results='asis'}
f_setting_dtf_s <- f_setting_dtf[VE_threshold == 0 & percentile_rank == 1 & LOH_HLA == 'strict_LOHHLA']

f_setting_dtf_s[, median(delta_n),
  by = 'project_extended'][order(V1)] %>%
  saas()
```

# Next steps

Do leave one tumor type out identification of 'optimal settings', i.e. find all factor levels having an ES >= .1 for instance across all tumor types except the one to be tested; then assess $delta_n$ filtered down to these settings for this particular tumor type.

<!--  vim: set tw=0 -->
