---
title: "Regressing out confounding factors in immunoediting analysis"
author: "Maarten Slagter"
output:
    html_document:
        toc: true
        theme: journal
---

In this document we aggregate sub-analyses to estimate editing at the
tumor-type level, correcting tumor types for sub-analysis composition.

Load in an overview of all regressions, i.e. one for combination of a
tumor type, pipeline setting and immunoediting analysis setting.
Filter away analyses for which sampling did not converge as basic QC.

```{r, init, warning=FALSE}
source('~/antigenic_space/bin/init.R')
knitr::opts_chunk$set(cache = T, include = T)

source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

setting_dtf <- compile_all_coef_overview(
  redo = F,
  ncores = 24,
  reg_method = 'bayesian_unbiased',
  include_non_ds_tallies = T,
  z_normalize = F
)

f_setting_dtf <- format_coef_overview(
  dtf = setting_dtf,
  pick_allele_method = 'none',
  # plot_fishtails = 'project',
  plot_fishtails = NULL,
  filter_intercept = F,
  intercept_filter_error = 4,
  rc_filter_error = NULL,
  delta_filter_error = NULL
)
```

Throughout this document, `estimate` refers to the slope divided by
the intercept (>0), which is interpretable as the mean fractional loss
in neo-antigen yield rate (NAYR) between patients with PS = 0 and PS =
1.

    Negative (positive) estimate -> editing/depletion (enrichment) of 
    neo-antigens
    Positive evid_ratio -> editing
    post_prob close to 1 -> editing


# Characterization of inference quality

```{r, eval=F, results='asis', warning=FALSE}
# setting_dtf[, summary(log2_intercept_cov)]
# setting_dtf[, summary(log2_ol_cov)]

## An SE of 1/2 of the estimate is still acceptable. Enforcing such a threshold
## on the slope will enrich for significant results however.
breaks <- c(-Inf, -2, -1, 0, Inf)

ov <- setting_dtf[, 
  .(.N, 'mean_nayr_diff' = mean(yr_fractional_change)),
  keyby = list(
    'nayr_diff_error' = cut(log2_est_error, breaks = breaks),
    'intercept_cov' = cut(log2_intercept_cov, breaks = breaks),
    'ol_cov' = cut(log2_ol_cov, breaks = breaks)
    )] %>%
  .[, 'frequency' := scales::percent(N / sum(N))] %>%
  .[, 'cum_frequency' := scales::percent(cumsum(N / sum(N)))] %>%
  { . }

knitr::kable(ov)
```

Estimate error is predominantly determined by intercept error, which 
is probably a good proxy for the number of included patients

```{r, estimate_stat_plots, warning=FALSE}
# setting_dtf[, hist(log2_intercept_cov, breaks = 1000)]
# setting_dtf[, hist(log2_ol_cov, breaks = 1000)]
# setting_dtf[, hist(log2_est_error, breaks = 1000)]
setting_dtf %>%
  dplyr::select(log2_intercept_cov, log2_ol_cov, log2_est_error) %>%
  GGally::ggpairs(diag = list(continuous = 'barDiag'), bins = 100)
```

# Which tumor types are indicated to have undergone editing?

```{r, evidence_ratio_fishtail, warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses', 'immune_editing',
    'continuous_IE_detection_init.R'))

p1 <- var_vs_error(setting_dtf, y = 'log2_evid_ratio') +
  ylab('log2 evidence ratio\n(>0 in agreement with immunoediting)')
print_plot(p1)
```

```{r, nayr_fishtail, dependson='evidence_ratio_fishtail', warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses', 'immune_editing', 'continuous_IE_detection_init.R'))

max_y <- .2
p1 <- var_vs_error(setting_dtf, y = 'yr_fractional_change') +
  scale_y_continuous(
    name = 'Fractional change in YR\nbetween PS = 0 and PS = 1',
    breaks = seq(-1, 1, by = .2),
    limits = c(-max_y, max_y)
  )
print_plot(p1)
```

-log2(1/4) = 2 ==> 2 corresponds to a standard error of 1/4, which is still
relatively big compared to the effect size we maximally to see (-.05).

0.05 (.0675) corresponds to ~4.

```{r, evidence_ratio_fishtail_strict, warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses', 'immune_editing',
    'continuous_IE_detection_init.R'))

# p1 <- qplot(y = log2_evid_ratio,
#   x = -log2_est_error, data = setting_dtf, geom = 'hex') +
#   geom_smooth()
p1 <- qplot(y = log2_evid_ratio, x = estimate, data = setting_dtf, geom = 'hex') +
  geom_smooth()
# p1 <- var_vs_error(setting_dtf, y = 'log2_evid_ratio') +
#   ylab('log2 evidence ratio\n(>0 in agreement with immunoediting)')
print_plot(p1)
```

# Do HLA alleles differ in average neo-antigen yield rate?

<!-- If sub-analyses are filtered for estimation error only leniently, invididual
     alleles appear incoherent in terms of NAYR at PS = 0 (i.e. the intercept).
     With more strict filtering, differences between
     alleles vanish.  -->

```{r, allele_intercept, warning=FALSE}
for (thresh in rev(c(-5, -2))) {
  l_dtf <- setting_dtf[intercept_est_error / intercept_estimate <= .2] %>%
    .[log2_est_error <= thresh]
  y_range <- NULL
  y_range <- c(0, l_dtf[, quantile(intercept_estimate, .8)])
  p <- l_dtf %>%
    pipe_row_print %>%
    ggplot(mapping = aes(x = focus_allele, y = intercept_estimate)) +
      geom_boxplot(outlier.size = 0) +
      xlab('Focus allele') +
      scale_y_continuous(name = 'Intercept', limits = y_range) +
      theme_fas(legend.key.width = unit(5, 'mm')) +
      facet_wrap(~project_extended, nrow = 4, labeller = label_parsed) +
      rotate_x_labels(90)

  # fn <- file.path(img_loc, 'bayesian_cont-intercept_variation.png')
  # ggsave(filename = fn, plot = p, height = 20, width = 20, unit = 'cm')
  print(p)
}
```

# Averaging NAYR loss within tumor types

<!-- Some indicate editing whereas others indicate
     preferential enrichment, within tumor types. Is there a pattern here?  Not
     really, A1101 highly consistent with editing for pan-cancer analyses but
     indicating enrichment for tumor type X. Since the frequency of all settings is
     not 100% equal between tumor types due to stochastic model failing, it's going
     to be important to regress out differences in model composition between tumor
     types when comparing tumor types. -->

Weight depletion estimates by their estimation error.  The here reported
credibility intervals are averages of the credibility intervals of subanalyses,
which is what we should want here. In contrast, a CI over the aggregate of all
sub-analyses, as lm() would give, would give overly narrow bounds as the
aggregated sub-analyses are far from independent from each other. The downside
of the 'clean' estimates in this section is that they are not corrected for
variation is subanalysis composition between tumor types, which is substantial
(see below).

```{r, average_estimates, warning=FALSE}
t_dat <- summarize_by_project(setting_dtf)
DT::datatable(t_dat)
```

```{r, fisher_plot_lenient, dependson='average_estimates', warning=FALSE}
forest_plot(t_dat)
```

The same, but now stringently filtered, doesn't make much of a difference
because sub-analyses were already weighted by estimation error.

```{r, stringent_average_estimates, warning=FALSE}
t_dat <- setting_dtf[log2_est_error <= -2] %>%
  summarize_by_project()
DT::datatable(t_dat)
```

```{r, fisher_plot_stringent, warning=FALSE}
forest_plot(t_dat)
```

# ANOVA to 'correct' for differences in sub-analysis composition between tumor
types

We model all estimated coefficients in a linear model to tease apart to what
degree indvidual modelling settings contribute to estimated depletion
coefficients.

```{r, load_brms_model, include=F, eval=F, warning=FALSE}
## Fixed effects brms approach. Waaaaaay too slow
# pacman::p_load('session')
# session::save.session(file='~/session.RSession')

chains = 16
mod_fn <- file.path(rds_dir,
  glue::glue('NAYR_loss_complete_blm{make_flag(chains)}.rds'))
if (!file.exists(mod_fn)) {
  b_mod <- brms::brm(estimate|se(est_error) ~ (focus_allele +
      expression_threshold + sts_filtering +
      VE_threshold + percentile_rank + overlap_var + patient_inclusion_crit +
      LOH_HLA + analysis_name | project_extended),
    data = setting_dtf[log2_est_error <= 2], cores = chains, chains = chains)
  saveRDS(b_mod, mod_fn)
} else {
  b_mod <- readRDS(mod_fn)
  # summary(mod)
}
```

```{r, load_brms_model, include=F, eval=F, warning=FALSE}
## Hierarchical reduced, brms model
# pacman::p_load('session')
# session::save.session(file='~/session.RSession')

chains = 16
mod_fn <- file.path(rds_dir,
  glue::glue('NAYR_loss_complete_blm{make_flag(chains)}.rds'))
if (!file.exists(mod_fn)) {
  b_mod <- brms::brm(estimate|se(est_error) ~
    (focus_allele + VE_threshold + patient_inclusion_crit +
     LOH_HLA + analysis_name | project_extended),
    data = setting_dtf[log2_est_error <= 2], cores = chains, chains = chains)
  saveRDS(b_mod, mod_fn)
} else {
  b_mod <- readRDS(mod_fn)
  # summary(mod)
}
```

```{r, load_brms_model, include=F, eval=F, warning=FALSE}
## Hierarchical reduced, brms model
# pacman::p_load('session')
# session::save.session(file='~/session.RSession')

grp_vars <- c('focus_allele', 'VE_threshold', 'patient_inclusion_crit',
  'LOH_HLA', 'analysis_name')
grp_vars <- c('focus_allele', 'VE_threshold', 'patient_inclusion_crit',
  'expression_threshold', 'LOH_HLA', 'analysis_name', 'sts_filtering',
  'percentile_rank', 'overlap_var')

if (F) {
  t_dat <-
    setting_dtf[log2_est_error <= 2, .(
      'estimate' = sum(estimate/est_error^2) / sum(1 / est_error^2),
      'est_error' = mean(est_error)), c(grp_vars, 'tumor_type')]
  sel <- f_setting_dtf[, .N, by = c('tumor_type', grp_vars)][2][, !'N']
  setkeyv(setting_dtf, colnames(sel))
  setting_dtf[sel]
} else {
  t_dat <- f_setting_dtf
  # table(f_setting_dtf$tumor_type)
}

c_formula <-
  as.formula(sprintf('estimate|se(est_error) ~ (%s | tumor_type)',
      paste(grp_vars, collapse = ' + ')))
library(brms)

chains = 16
mod_id <- paste(grp_vars, collapse = '_')
mod_fn <- file.path(rds_dir,
  glue::glue('NAYR_loss_complete_blm\\
    {make_flag(chains)}\\
    {make_flag(mod_id)}.rds'))
# back_up(mod_fn); file.remove(mod_fn)
# back_up(mod_fn)
if (!file.exists(mod_fn)) {
  b_mod <- brms::brm(c_formula, data = t_dat,
    prior = c(
      prior_string("normal(0, .1)", class = 'Intercept'),
      prior_string("normal(0, .5)", class = 'sd')
    ),
    cores = chains, chains = chains, 
    sample_prior = 'yes', iter = 1000)
  saveRDS(b_mod, mod_fn)
} else {
  b_mod <- readRDS(mod_fn)
  # summary(mod)
}
REs <- brms::ranef(b_mod)
FEs <- brms::fixef(b_mod)
```

```{r, include = F, eval = F, warning=FALSE}
library(lme4)

c_formula <-
  sprintf('estimate ~ (%s | tumor_type)',
    paste(grp_vars, collapse = ' + ')) %>%
  as.formula()

me_mod <- lmer(
  formula = c_formula,
  data = setting_dtf, REML = T,
  weights = 1 / setting_dtf$est_error
)
ranef(me_mod)[[1]] %>% select(`(Intercept)`)
ranef(me_mod)[[1]] %>% select(`VE_threshold5`)
ranef(me_mod)[[1]] %>% pull(VE_threshold5)
ranef(me_mod)[[1]] %>% apply(2, median)
# saveRDS(me_mod, file.path(rds_dir, 'lmer_mod.rds'))
library(lme4)
str(ranef(me_mod))
dotplot(ranef(me_mod), setting_dtf)
```

```{r, warning=FALSE}
levels(setting_dtf$VE_threshold)
me_mod <- lmer(
  formula = c_formula,
  data = setting_dtf, REML = T,
  weights = 1 / setting_dtf$est_error
)
summary(me_mod)
```

```{r, warning=FALSE}
b_mod <- brms::make_stancode(c_formula, data = t_dat,
  prior = c(
    prior_string("normal(0, .2)", class = 'Intercept'),
    prior_string("normal(0, .5)", class = 'sd')
  ), sample_prior = 'yes')

b_data <- brms::make_standata(c_formula, data = t_dat,
  prior = c(
    prior_string("normal(0, .2)", class = 'Intercept'),
    prior_string("normal(0, .5)", class = 'sd')
  ))

sm <- rstan::stan_model(
  file = NULL, model_code = b_mod, data = b_data
)
```

```{r, warning=FALSE}
library(broom)
library(brms)
summary(b_mod, prob = 0.90)
tidy(b_mod)
dim(REs)
dimnames(REs[[1]])
REs[[1]][, , 'Intercept'] %>%
  as.data.frame %>%
  dplyr::arrange(Estimate)
parnames(b_mod)
# b_mod_r <- rename_pars(b_mod)
# parnames(b_mod_r)
```

```{r, warning=FALSE}
project_hypos <-
  purrr::map_dfr(rownames(REs[[1]][,  , 1]), function(pe) {
    RE_name <- glue::glue('r_tumor_type[{pe},Intercept]')
    hypo_string <- as.character(glue::glue('b_Intercept + {RE_name} < 0'))
    hypo <- brms::hypothesis(b_mod, class = NULL, hypothesis = hypo_string)
    # hypo <- brms::hypothesis(b_mod, class = NULL, hypothesis = hypo_string,
    #   alpha = .001)
    ret_val <- hypo$hypothesis
    ret_val$tumor_type <- pe
    return(ret_val)
  }) %>%
  dplyr::arrange(-Estimate) %>%
  dplyr::mutate(tumor_type =
    factor(tumor_type, levels = unique(tumor_type))) %>%
  dplyr::mutate(project_extended =
    tumor_types_inv[as.character(tumor_type)]) %>%
  dplyr::mutate(project_extended = factor(project_extended,
      levels = project_extended))
```

```{r, eval = F, warning=FALSE}
pacman::p_load('hrbrthemes')
theme_set(hrbrthemes::theme_ipsum_rc())
bayesplot_theme_set(hrbrthemes::theme_ipsum_rc())
```

```{r, warning=FALSE}
setDT(project_hypos)
project_hypos[, p_label := sprintf('italic(p)==%s', fancy_scientific(Post.Prob))]
# project_hypos[, p_label := parse(text = p_label)]
tail(project_hypos)

v_eps <- .04
p <- ggplot(project_hypos, aes(x = project_extended, ymin = CI.Lower,
    y = Estimate, ymax = CI.Upper)) +
  geom_hline(yintercept = 0, colour = 'grey50', size = .3) +
  geom_linerange() +
  geom_point() +
  geom_text(data = project_hypos[Post.Prob >= .95],
    mapping = aes(y = CI.Upper + v_eps, x = project_extended, label = p_label),
    size = 2, parse = T, hjust = 0) +
  geom_text(data = project_hypos[Post.Prob <= .05],
    mapping = aes(y = CI.Lower - v_eps, x = project_extended, label = p_label),
    size = 2, parse = T, hjust = 1) +
  # geom_text(data = setDT(project_hypos)[abs(pmin(Post.Prob - c(0, 1))) <= .05],
  #   mapping = aes(y = CI.Upper + v_eps, x = project_extended, label = p_label), size = 2,
  #   parse = T, hjust = 0) +
  scale_x_discrete(
    name = '',
    labels = parse(text = levels(project_hypos$project_extended))
  ) +
  coord_flip()

print_plot(
  p, fn = file.path(img_loc, 'b_rm_tumor_type_forest.png'),
  w = 8.7, h = 10)
```

Correct estimates for subanalysis composition with plain linear model/ANOVA

```{r, load_lm_model, cache=T, warning=FALSE}
mod_fn <- file.path(rds_dir, 'NAYR_loss_complete_lm.rds')
# file.remove(mod_fn)
# back_up(mod_fn)
# rm('mod')
if (!file.exists(mod_fn) && !exists('mod')) {
  mod <- lm(estimate ~ (focus_allele + project_extended +
      expression_threshold + sts_filtering +
      VE_threshold + percentile_rank + overlap_var + patient_inclusion_crit +
      LOH_HLA + analysis_name)^2,
    data = setting_dtf, weights = 1/(est_error^2))
  saveRDS(mod, mod_fn)
} else {
  mod <- readRDS(mod_fn)
}

coef_df <- summary(mod)$coefficients %>%
  as.data.frame %>%
  tibble::rownames_to_column('coef') %>%
  normalize_colnames %>%
  dplyr::rename(std_error = std__error) %>%
  dplyr::rename(p = `pr(>|t|)`) %>%
  dplyr::rename(t = t_value) %>%
  { . }
```

Which tumor types are significantly immunoedited? We attempted to correct for
potential subanalysis composition between tumor types by fitting a linear fixed
effects model to the aggregate of all Bayesian regressions, in which all
immunoediting settings and neo-antigen prediction pipeline settings were
included as explanatory covariates, in order to estimate the individual effects
of all said settings, and their interactions, on the resulting estimate of NAYR
loss. Using this analysis, differences between tumor types can be normalized
out.

```{r, include = F, dependson='load_lm_model', warning=FALSE}
# focus_allele = 'A1101'
# project_extended = 'Pan*\'-\'*cancer'
# setting_dtf[focus_allele == parent.frame(4)$focus_allele &
#     project_extended == parent.frame(4)$project_extended,
#     sum(yr_fractional_change/est_error^2) / sum(1 / est_error^2)]
# summary(mod)$coefficients['focus_alleleA1101', ]
# summary(mod)$coefficients['project_extendedPan*\'-\'*cancer', ]
# summary(mod)$coefficients['focus_alleleA1101:project_extendedPan*\'-\'*cancer', ]
# coef_df %>% filter(grepl(focus_allele, coef))
# coef_df %>% filter(grepl(gsub('\\*', '\\\\*', project_extended), coef))
# coef_df %>% filter(grepl('^project_ex[^:]*$', coef))
```

<!-- Strikingly, uterine endometrial appeared most edited when not correcting for
     analysis composition but appears slighlty enriched for neo-antigen mutations
     when correcting for subanalysis composition. -->

```{r, corrected_tumor_types, dependson='load_lm_model', warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

grand_mean <- coef_df[coef_df$coef == '(Intercept)', ]
dof <- nrow(setting_dtf) - nrow(coef_df)

regex = '^project_ex[^:]*$'

formatted_coefs <- coef_df %>%
  dplyr::filter(grepl(regex, coef)) %>%
  dplyr::mutate(coef = gsub('project_extended', '', coef)) %>%
  dplyr::mutate(coef = tumor_types[coef]) %>%
  dplyr::filter(!is.na(coef)) %>%
  sum_estimates(grand_mean) %>%
  dplyr::arrange(estimate_corr) %>%
  dplyr::select(coef, everything()) %>%
  { . }

print_dat <- formatted_coefs %>%
  pipe_row_print %>%
  # dplyr::arrange(desc(estimate)) %>%
  dplyr::select(-estimate, -std_error, -t, -p)

if (test_rendering()) {
  DT::datatable(print_dat)
}
```

P-values are inflated as the individual observations on which they are based
(sub-analyses) are not independent. This interdependence should not affect effect sizes however.

```{r, tumor_volcano, dependson='load_lm_model', warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

print_plot(
  coef_volcano(formatted_coefs),
  fn = file.path(img_loc, 'tumor_type_volcano.png'),
  w = 20, h = 10)

print_plot(
  coef_volcano(formatted_coefs, mod = function(v)
    switch(v, 'p' = 'p_corr', '-log10(p)' = '-log10(p_corr)',
      'estimate' = 'estimate_corr')
  ),
  fn = file.path(img_loc, 'tumor_type_volcano_corrected.png'),
  w = 20, h = 10)
```

Regression coefficients for all other 'settings'

```{r, fixed_effects, warning=FALSE}
print_first_order_effects <- function(coef_name = 'expression_threshold') {
  regex = sprintf('^%s[^:]*$', coef_name)

  formatted_coefs <- coef_df %>%
    dplyr::filter(grepl(regex, coef)) %>%
    dplyr::mutate(coef = gsub(coef_name, '', coef)) %>%
    sum_estimates(grand_mean) %>%
    { . }

  cat(coef_name, '\n')
  formatted_coefs %>%
    pipe_row_print %>%
    DT::datatable()
}

vars <- c('focus_allele', 'expression_threshold', 'VE_threshold',
  'percentile_rank', 'overlap_var', 'patient_inclusion_crit', 'LOH_HLA',
  'analysis_name')
for (v in vars) {
  print_first_order_effects(v)
}
```

```{r, other_coef_volcano, warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

formatted_coefs <- coef_df %>%
  dplyr::filter(grepl('^[^:]*$', coef)) %>%
  dplyr::filter(!grepl('project_extended', coef)) %>%
  dplyr::filter(!grepl('Intercept', coef)) %>%
  sum_estimates(grand_mean) %>%
  setDT %>%
  format_formatted_coefs() %>%
  { . }

print_plot(coef_volcano(formatted_coefs) +
  theme(legend.direction = 'vertical', legend.position = 'right'),
  fn = file.path(img_loc, 'lm_coefficient_volcano.png'), w = 14, h = 10)
```

```{r, warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

formatted_coefs <- coef_df %>%
  dplyr::mutate(i_term = as.integer(grepl(':', coef)) + 1) %>%
  dplyr::mutate(i_term = factor(i_term, levels = c(1, 2),
      labels = c('no', 'yes'))) %>%
  # dplyr::filter(!(grepl('project_extended', coef) & i_term == 'yes')) %>%
  dplyr::filter(!grepl('project_extended', coef)) %>%
  # dplyr::filter(grepl('LOH_HLA', coef)) %>%
  format_formatted_coefs() %>%
  { . }

# ggplot(formatted_coefs, aes(x = estimate, fill = i_term, col = i_term)) +
#   geom_freqpoly()

label_dat <- formatted_coefs[abs(estimate) >= .2 & -log10(p) >= 10]
print(label_dat)

print_plot(coef_volcano(formatted_coefs, label_dat = label_dat) +
  theme(legend.direction = 'vertical', legend.position = 'right'),
  fn = file.path(img_loc, 'lm_coefficient_volcano_including_interactions.png'),
  w = 14, h = 10)
```

# Tumor type specific 'deconvolution' analyses

This doesn't work as tumor types and their intercept terms are no longer against
a shared reference and hence cannot be compared against each other.

```{r, tumor_specific_load_lm_model, cache=T, eval = F, warning=FALSE}
library(furrr)
plan(transparent)
plan(multicore, workers = 20)

f <- estimate ~ (focus_allele + expression_threshold +
  VE_threshold + percentile_rank + overlap_var + patient_inclusion_crit +
  sts_filtering + LOH_HLA + analysis_name)^2

## MSI-H tumors, VE_threshold and patient_inclusion_crit do not work here
f_2 <- estimate ~ (focus_allele + expression_threshold +
  percentile_rank + overlap_var + sts_filtering + LOH_HLA + analysis_name)^2

grp_vars <- c('project_extended', 'focus_allele', 'sts_filtering',
  'expression_threshold', 'VE_threshold', 'percentile_rank', 'overlap_var',
  'patient_inclusion_crit', 'LOH_HLA', 'analysis_name')

## Identify which variables are missed in formula
# sel <- setting_dtf[, .N, by = grp_vars][1, !"N", with = F]
# setkeyv(setting_dtf, colnames(sel))
# setting_dtf[sel]
# setting_dtf[, .N, by = grp_vars]
# setting_dtf[, .SD, by = grp_vars][1]

mods <- furrr::future_map(auto_name(levels(setting_dtf$project_extended)),
  function(pe) {
  pe_plain <- tumor_types[pe]
  mod_fn <- file.path(rds_dir,
    glue::glue('NAYR_loss_complete_lm-{pe_plain}.rds'))
  if (!file.exists(mod_fn)) {
    mod <- tryCatch(lm(formula = f, data = setting_dtf[project_extended == pe],
      weights = 1/(est_error^2)),
      error = function(e) { print(pe); print(e); NULL })
    if (is.null(mod)) {
      mod <- tryCatch(lm(formula = f_2, data = setting_dtf[project_extended == pe],
        weights = 1/(est_error^2)),
        error = function(e) { print(pe); print(e); NULL })
    }
    if (!is.null(mod)) saveRDS(mod, mod_fn)
  } else {
    mod <- tryCatch(readRDS(mod_fn), error = function(e) { print(e); NULL })
  }
  return(mod)
})

# coef_df <- summary(mod)$coefficients %>%
#   as.data.frame %>%
#   tibble::rownames_to_column('coef') %>%
#   normalize_colnames %>%
#   dplyr::rename(std_error = std__error) %>%
#   dplyr::rename(p = `pr(>|t|)`) %>%
#   dplyr::rename(t = t_value) %>%
#   { . }
map(mods, ~coef(summary(.x))[1, 1])
```

## Effect of enriching for high probability sub-analyses

Fishtail plot of analysis filtered for LOHHLA_strict and TR.

```{r, TR_highligh_fishtail, warning=FALSE}
source(file.path('~/antigenic_space', 'maarten-analyses',
    'immune_editing', 'continuous_IE_detection_init.R'))

sel <-
  expr((expression_threshold == 5000 | VE_threshold == 5) &
  patient_inclusion_crit == 'TR' &
  LOH_HLA == 'strict_LOHHLA')

p <- highlight_fishtail(setting_dtf, 'estimate', highlight_code = sel)

print_plot(p, w = 34, h = 20, fn = file.path(img_loc, 'enriching.png'))
```

Bidirectional forest showing that enriching for high expression, LOHHLA strict
patients and patients without IT-resistant patients indeed strengthens IE
estimates.

```{r, bidirectional_forest, fig.width = 17.4/2.54, fig.height = 12/2.54, warning=FALSE}
p_dat <- merge(
  summarize_by_project(setting_dtf),
  summarize_by_project(setting_dtf[eval(sel)]),
  by = 'tumor_type'
)
p_dat[, 'project_extended' :=
  setNames(names(tumor_types), tumor_types)[as.character(tumor_type)]]

hl_dat <- p_dat[sign(V3.y) != sign(V3.x)]
library(ggrepel)

tot_range <- p_dat %>%
  select(-tumor_type, -project_extended) %>%
  as.matrix %>%
  range

sm <- .5
p <- ggplot(p_dat, aes(color = project_extended, y = V2.y, x = V2.x,
    label = project_extended, fill = project_extended)) +
  geom_point(size = 5, alpha = .2) +
  geom_point(size = 2) +
  ## Vertical lines
  geom_vline(xintercept = 0, color = 'grey20') +
  geom_hline(yintercept = 0, color = 'grey20') +
  geom_abline(intercept = 0, slope = 1, color = 'grey20', linetype = 3) +
  geom_segment(aes(x = V2.x, y = V1.y, xend = V2.x, yend = V3.y), alpha = .5,
    size = 1 * sm, show.legend = F) +
  geom_segment(aes(x = V1.x, y = V2.y, xend = V3.x, yend = V2.y), alpha = .5,
    size = 1 * sm, show.legend = F) +
  geom_segment(data = hl_dat, aes(x = V2.x, y = V1.y, xend = V2.x, yend = V3.y),
    alpha = .5, size = 2 * sm, show.legend = F) +
  geom_segment(data = hl_dat, aes(x = V1.x, y = V2.y, xend = V3.x, yend = V2.y),
    alpha = .5, size = 2 * sm, show.legend = F) +
  ggrepel::geom_label_repel(data = hl_dat, force = 1000, show.legend = F,
    parse = T, size = 2, color = 'grey10') +
  scale_x_continuous(name = 'log2 diff NAYR between PS = 0 and PS = 1\n(before enrichment)', limits = NULL) +
  scale_y_continuous(name = 'log2 diff NAYR between PS = 0 and PS = 1\n(after enrichment)', limits = NULL) +
  # theme_fas(aspect.ratio = 1)
  theme_fas()


if (F) {
  comb_range <- c(
    min(c(p_dat$V1.x, p_dat$V1.y)) * 1.05,
    max(c(p_dat$V3.x, p_dat$V3.y)) * 1.05
  )

  comb_range <- c(
    min(c(p_dat$V2.x, p_dat$V2.y)) * 1.05,
    max(c(p_dat$V2.x, p_dat$V2.y)) * 1.05
  )

  print_plot(p + coord_cartesian(
    xlim = comb_range,
    ylim = comb_range
  ), w = 20, h = 20)
} else {
  xlimits <- 1.05 * range(p_dat$V2.x)
  ylimits <- 1.05 * range(p_dat$V2.y)
  print_plot(p + coord_cartesian(
    xlim = xlimits,
    ylim = ylimits
  ), w = 17.4, h = 10)
}
```

```{r, warning=FALSE}
print_plot(p + coord_cartesian(
  xlim = range(p_dat$V2.x) * 1.05,
  ylim = range(p_dat$V2.y) * 1.05
), w = 20, h = 20, fn = file.path(img_loc, 'enriching.png'))
```

```{r, eval = F, warning=FALSE}
setting_dtf[, .SD[order(estimate)][1], by = project_extended] %>%
  .[, .(project_extended, LOH_HLA, patient_inclusion_crit, analysis_name,
    VE_threshold, expression_threshold)]
```

# The necessity to correct for subanalysis composition

Especially the TR and LOHHLA covariates, shown important to final results above,
are shown to be unevenly present across tumor types.

```{r, analysis_composition, warning=FALSE}
plot_analysis_composition <- function(coef_name = 'expression_threshold') {
  setting_dtf[log2_est_error <= -2, .N, keyby = c('project_extended', coef_name)] %>%
    .[, 'frac' := N / sum(N), by = project_extended] %>%
    ggplot(aes_string(x = 'project_extended', y = 'frac', fill = coef_name)) +
    geom_col() +
    scale_x_discrete(name = '') +
    rotate_x_labels(90) +
    coord_flip() +
    theme_fas()
}

for (v in vars) {
  print(plot_analysis_composition(v))
}
```

# Editing preferentially in tumor types in which NAYR doesn't correlate with
immune cell infiltration?

```{r, depletion_immune_correlation, eval = F, warning=FALSE}
cor_dtf <- readRDS(file.path(rds_dir, 'xcell_neo_immune_correlations.rds'))
cor_dtf[, tumor_type := tumor_types[project_extended]]
i_dat <- merge(t_dat, cor_dtf)
i_dat[, cor(V2, cor)]
qplot(data = i_dat, x = V2, y = `cor`)
```

```{r, eval = F, warning=FALSE}
xcell_estimates <- readRDS(file.path(rds_dir, 'xcell_estimates.rds'))
xcell_estimates[1:5, 1:5]
```

# HLA downsampling to test stability of current estimates

With less HLA alleles, would have gotten the same estimates?

```{r, warning=FALSE}
all_alleles <- unique(setting_dtf$focus_allele)
N_alleles <- length(all_alleles)

all_combinations <- map_dfr(1:N_alleles, function(t) {
  all_combs <- gtools::combinations(n = N_alleles, r = t,
    repeats.allowed = F) %>%
    { all_alleles[.] } %>%
    matrix(ncol = t, byrow = F) %>%
    { . }

  ## Split into list of tuples (list of lists actually)
  all_combs <- split(
    t(all_combs), rep(seq(1, length(all_combs), by = t), each = t))

  imap_dfr(all_combs, function(comb, i) {
    dtf_s <- setting_dtf[focus_allele %in% comb]
    t_dat <- dtf_s[, .(
      wa_var(.SD, 'ci_lower'),
      wa_var(.SD, 'estimate'),
      wa_var(.SD, 'ci_upper')), by = project_extended] %>%
      .[order(V2)]
  }, .id = 'i')
}, .id = 't')

setDT(all_combinations)
all_combinations[, 'id' := paste(t, i, sep = '-')]
id_levs <- all_combinations[, naturalsort::naturalsort(unique(id))]
all_combinations[, id := factor(id, levels = id_levs)]
all_combinations[, i := NULL]
```

```{r, downsampling_forest, fig.width = 25/2.54, fig.height = 25/2.54, warning=FALSE}
p <- ggplot(all_combinations,
  aes(x = id, y = V2, ymin = V1, ymax = V3, colour = t)) +
  geom_hline(yintercept = 0, color = 'grey20') +
  geom_point() +
  geom_linerange() +
  ylab('log2 diff NAYR between PS = 0 and PS = 1') +
  scale_x_discrete(name = 'HLA allele combination') +
  scale_colour_discrete(name = '# of alleles included') +
  theme_fas() +
  facet_wrap(~project_extended, labeller = label_parsed)

if (test_rendering()) {
  print(p)
} else {
  test_plot(print(p), w = 34, h = 20)
}
```

# Another validation of TR

```{r, warning=FALSE}

```
